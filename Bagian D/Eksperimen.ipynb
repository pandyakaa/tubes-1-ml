{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar 1 - Bagian D \n",
    "\n",
    "## Kelompok XX K- 3 \n",
    "1. Pandyaka Aptanagi - 13517003\n",
    "2. I Putu Gede Wirasuta - 13517015\n",
    "3. M. Rifky I. Bariansya - 13517081\n",
    "4. Gardahadi - 13517144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Import Library Standar dan Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Standard Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DTL Classifier\n",
    "from clf.mlp import MyMlp\n",
    "from clf.c45 import C45\n",
    "from clf.utils import read_csv, scale_data\n",
    "from clf.c45_numeric_handler import process_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Mendefinisikan Fungsi Bantuan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function Import Data\n",
    "\n",
    "def import_data(path, sep=',',dropna=True, drop_duplicates=True):\n",
    "    data = pd.read_csv(path, sep)\n",
    "    print(\"Import Berhasil\")\n",
    "    print(\"Banyaknya baris dan kolom\", data.shape)\n",
    "    print(\"Banyaknya data duplicate\", data.duplicated().sum())\n",
    "    data = data.drop_duplicates() if drop_duplicates else data\n",
    "    data = data.dropna() if dropna else data\n",
    "#     print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Extract Input and Output\n",
    "\n",
    "def extract_feature_target(data, output):\n",
    "    y = data[output]\n",
    "    x = data.drop(output, axis=1)\n",
    "    #print(x.columns) #optional\n",
    "    #print(y.head()) #optional\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split train test data (default test_size = 0.4)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_data(x,y, _test_size = 0.4): \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =_test_size,\n",
    "                                                        random_state =100)\n",
    "    print(\"Training Data :\")\n",
    "    print(x_train.head(), y_train.head()) #\n",
    "    print(\" Testing Data :\" )\n",
    "    print(x_test.head(), y_test.head()) #\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to evaluate score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def scoring(model, x_test, y_test) :\n",
    "    y_predict = model.predict(x_test)\n",
    "    print(\"Model Score based on test data\")\n",
    "    print(accuracy_score(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 1 : Eksperimen Skema Hold-out Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Pembelajaran DTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pembelajaran ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 2 : Eksperimen Skema 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Pembelajaran DTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Berhasil\n",
      "Banyaknya baris dan kolom (150, 5)\n",
      "Banyaknya data duplicate 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('clf', <clf.c45.C45 object at 0x000001C243DE8C18>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import things\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "df = import_data('../Bagian C/datasets/iris.csv',',')\n",
    "x, y = extract_feature_target(df, ' species')\n",
    "\n",
    "# Create MyC45\n",
    "myc45 = C45()\n",
    "myc45.label = list(x.columns)\n",
    "myclf = MyMlp(input_layer, hidden_layer, output_layer, epochs=2500, learning_rate=0.02)\n",
    "x_temp = process_numeric(np.vectorize(str)(x.values), y.values)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', myc45)\n",
    "])\n",
    "\n",
    "pipeline.set_params(clf = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "20.0%\n",
      "0.0%\n",
      "0.0%\n",
      "40.0%\n",
      "0.0%\n",
      "0.0%\n",
      "0.0%\n"
     ]
    }
   ],
   "source": [
    "dtl_cross_validate = cross_validate(pipeline, x_temp, y.values, cv=10, scoring='accuracy')\n",
    "for ts in dtl_cross_validate['test_score'] :\n",
    "    print(str(ts*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Pembelajaran ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('clf', <clf.c45.C45 object at 0x000001C243DE8C18>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', myclf)\n",
    "])\n",
    "\n",
    "pipeline.set_params(clf = classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "20.0%\n",
      "0.0%\n",
      "0.0%\n",
      "40.0%\n",
      "0.0%\n",
      "0.0%\n",
      "0.0%\n"
     ]
    }
   ],
   "source": [
    "ann_cross_validate = cross_validate(pipeline, x_temp, y.values, cv=10, scoring='accuracy')\n",
    "for ts in dtl_cross_validate['test_score'] :\n",
    "    print(str(ts*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 3 : Penyimpanan dan Pemanggilan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Menyimpan Model dalam file .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Memanggil Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagian 4 : Analisis Eksperimen Bagian 1 & 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Berhasil\n",
      "Banyaknya baris dan kolom (150, 5)\n",
      "Banyaknya data duplicate 3\n"
     ]
    }
   ],
   "source": [
    "df = import_data('../Bagian C/datasets/iris.csv',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length   sepal_width   petal_length   petal_width  species\n",
       "0           5.1           3.5            1.4           0.2   setosa\n",
       "1           4.9           3.0            1.4           0.2   setosa\n",
       "2           4.7           3.2            1.3           0.2   setosa\n",
       "3           4.6           3.1            1.5           0.2   setosa\n",
       "4           5.0           3.6            1.4           0.2   setosa"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = extract_feature_target(df, ' species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "num_attribs = list(x)\n",
    "\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    # ('selector', DataFrameSelector(num_attribs)),\n",
    "#     ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    # ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "  ])\n",
    "\n",
    "# cat_pipeline = Pipeline([\n",
    "#     ('selector', DataFrameSelector(cat_attribs)),\n",
    "#     ('label_binarizer', MyLabelBinarizer()),\n",
    "#   ])\n",
    "\n",
    "# preprocessor = FeatureUnion(transformer_list=[\n",
    "#     (\"num_pipeline\", num_pipeline),\n",
    "#     (\"cat_pipeline\", cat_pipeline),\n",
    "#   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clf.mlp import MyMlp\n",
    "from clf.c45 import C45\n",
    "from clf.utils import read_csv, scale_data\n",
    "from clf.c45_numeric_handler import process_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "[4, 3]\n"
     ]
    }
   ],
   "source": [
    "input_layer = len(list(x))\n",
    "print(input_layer)\n",
    "output_layer = len(set(y))\n",
    "print(output_layer)\n",
    "hidden_layer = [4, 3]\n",
    "print(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclf = MyMlp(input_layer, hidden_layer, output_layer, epochs=2500, learning_rate=0.02)\n",
    "myc45 = C45()\n",
    "myc45.label = list(x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '> 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '> 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '> 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '> 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '> 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '> 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['<= 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '<= 1.9' '<= 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['<= 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['<= 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']\n",
      " ['> 4.9' '<= 3.8' '> 1.9' '> 0.6']]\n",
      "---------------------------------\n",
      "<clf.c45.C45 object at 0x000001C243694588>\n",
      "-----------------------------------\n",
      "fit_time  mean  0.011585426330566407\n",
      "fit_time  std  0.0026555270534793537\n",
      "score_time  mean  0.0010622501373291015\n",
      "score_time  std  0.0006707116208901099\n",
      "test_score  mean  0.3820689655172414\n",
      "test_score  std  0.3811641221186584\n",
      "{'fit_time': array([0.01676011, 0.01027751, 0.00990462, 0.01137471, 0.00961018]), 'score_time': array([0.00120449, 0.00100136, 0.00099778, 0.00210762, 0.        ]), 'test_score': array([1.        , 0.6       , 0.        , 0.31034483, 0.        ])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    # ('processor', preprocessor), #Step1 - preprocess data\n",
    "    ('clf', LogisticRegression()) #step2 - classifier (default : LogisticRegression )\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "clfs = []\n",
    "# clfs.append(myclf)\n",
    "clfs.append(myc45)\n",
    "# clfs.append(SVC())\n",
    "# clfs.append(KNeighborsClassifier(n_neighbors=3))\n",
    "# clfs.append(DecisionTreeClassifier())\n",
    "# clfs.append(RandomForestClassifier())\n",
    "# clfs.append(GradientBoostingClassifier())\n",
    "\n",
    "for classifier in clfs:\n",
    "    pipeline.set_params(clf = classifier)\n",
    "    x_temp = process_numeric(np.vectorize(str)(x.values), y.values)\n",
    "    print(x_temp)\n",
    "    scores = cross_validate(pipeline, x_temp, y.values, cv=5, scoring='accuracy')\n",
    "    print('---------------------------------')\n",
    "    print(str(classifier))\n",
    "    print('-----------------------------------')\n",
    "    for key, values in scores.items():\n",
    "            print(key,' mean ', values.mean())\n",
    "            print(key,' std ', values.std())\n",
    "    print(scores)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

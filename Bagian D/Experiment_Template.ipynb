{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Standard Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Function and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Import Data\n",
    "\n",
    "def import_data(path, drop, sep,dropna=True, drop_duplicates=True):\n",
    "    data = pd.read_csv(path, sep)\n",
    "    print(\"Banyaknya baris dan kolom\", data.shape)\n",
    "    print(\"Banyaknya data duplicate\", data.duplicated().sum())\n",
    "    data = data.drop_duplicates() if drop_duplicates else data\n",
    "    data = data.dropna() if dropna else data\n",
    "    data = data.drop(drop,axis=1)\n",
    "    print(\"Banyaknya data setelah di drop\", data.shape)\n",
    "    #print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Extract Input and Output\n",
    "\n",
    "def extract_input_output(data, output):\n",
    "    y = data[output]\n",
    "    x = data.drop(output, axis=1)\n",
    "    #print(x.columns) #optional\n",
    "    #print(y.head()) #optional\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split train test data (default test_size = 0.4)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_data(x,y, _test_size = 0.4): \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =_test_size,\n",
    "                                                        random_state =100)\n",
    "   # print(x_train.head(), y_train.head()) #\n",
    "    #print(x_test.head(), y_test.head()) #\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to evaluate score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def scoring(model) :\n",
    "    y_predict = model.predict(x_train)\n",
    "    print(\"Model Score based on training data\")\n",
    "    print(accuracy_score(y_train, y_predict))\n",
    "    y_predict = model.predict(x_test)\n",
    "    print(\"Model Score based on test data\")\n",
    "    print(accuracy_score(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin #gives fit_transform method for free\n",
    "class MyLabelBinarizer(TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.encoder = LabelBinarizer(*args, **kwargs)\n",
    "    def fit(self, x, y=0):\n",
    "        self.encoder.fit(x)\n",
    "        return self\n",
    "    def transform(self, x, y=0):\n",
    "        return self.encoder.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, attribute_names):\n",
    "    self.attribute_names = attribute_names\n",
    "  def fit(self, X, y=None):\n",
    "    return self\n",
    "  def transform(self, X):\n",
    "    return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure y_train is balanced\n",
    "def plot_y_balance(y, df) : \n",
    "  ax = sns.countplot(y,label=\"Count\")       # M = 212, B = 357\n",
    "  C, N = y.value_counts()\n",
    "  print('Number of Churned: ',C)\n",
    "  print('Number of Not Churned : ',N) \n",
    "  df.isChurned.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "num_attribs = list(x_train.drop('userLevel',axis=1))\n",
    "cat_attribs = [\"userLevel\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    #('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "  ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_attribs)),\n",
    "    ('label_binarizer', MyLabelBinarizer()),\n",
    "  ])\n",
    "\n",
    "preprocessor = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('processor', preprocessor), #Step1 - preprocess data\n",
    "    ('clf', LogisticRegression()) #step2 - classifier (default : LogisticRegression )\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "clfs = []\n",
    "clfs.append(LogisticRegression())\n",
    "# clfs.append(SVC())\n",
    "# clfs.append(KNeighborsClassifier(n_neighbors=3))\n",
    "clfs.append(DecisionTreeClassifier())\n",
    "clfs.append(RandomForestClassifier())\n",
    "# clfs.append(GradientBoostingClassifier())\n",
    "\n",
    "for classifier in clfs:\n",
    "    pipeline.set_params(clf = classifier)\n",
    "    scores = cross_validate(pipeline, x_train, y_train,cv=3)\n",
    "    print('---------------------------------')\n",
    "    print(str(classifier))\n",
    "    print('-----------------------------------')\n",
    "    for key, values in scores.items():\n",
    "            print(key,' mean ', values.mean())\n",
    "            print(key,' std ', values.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

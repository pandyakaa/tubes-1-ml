{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Standard Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Function and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Import Data\n",
    "\n",
    "def import_data(path, sep,dropna=True, drop_duplicates=True):\n",
    "    data = pd.read_csv(path, sep)\n",
    "    print(\"Banyaknya baris dan kolom\", data.shape)\n",
    "    print(\"Banyaknya data duplicate\", data.duplicated().sum())\n",
    "    data = data.drop_duplicates() if drop_duplicates else data\n",
    "    data = data.dropna() if dropna else data\n",
    "    #print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Extract Input and Output\n",
    "\n",
    "def extract_input_output(data, output):\n",
    "    y = data[output]\n",
    "    x = data.drop(output, axis=1)\n",
    "    #print(x.columns) #optional\n",
    "    #print(y.head()) #optional\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split train test data (default test_size = 0.4)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_data(x,y, _test_size = 0.4): \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =_test_size,\n",
    "                                                        random_state =100)\n",
    "   # print(x_train.head(), y_train.head()) #\n",
    "    #print(x_test.head(), y_test.head()) #\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to evaluate score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def scoring(model) :\n",
    "    y_predict = model.predict(x_train)\n",
    "    print(\"Model Score based on training data\")\n",
    "    print(accuracy_score(y_train, y_predict))\n",
    "    y_predict = model.predict(x_test)\n",
    "    print(\"Model Score based on test data\")\n",
    "    print(accuracy_score(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin #gives fit_transform method for free\n",
    "class MyLabelBinarizer(TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.encoder = LabelBinarizer(*args, **kwargs)\n",
    "    def fit(self, x, y=0):\n",
    "        self.encoder.fit(x)\n",
    "        return self\n",
    "    def transform(self, x, y=0):\n",
    "        return self.encoder.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, attribute_names):\n",
    "    self.attribute_names = attribute_names\n",
    "  def fit(self, X, y=None):\n",
    "    return self\n",
    "  def transform(self, X):\n",
    "    return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyaknya baris dan kolom (150, 5)\n",
      "Banyaknya data duplicate 3\n"
     ]
    }
   ],
   "source": [
    "df = import_data('../Bagian C/datasets/iris.csv',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length   sepal_width   petal_length   petal_width  species\n",
       "0           5.1           3.5            1.4           0.2   setosa\n",
       "1           4.9           3.0            1.4           0.2   setosa\n",
       "2           4.7           3.2            1.3           0.2   setosa\n",
       "3           4.6           3.1            1.5           0.2   setosa\n",
       "4           5.0           3.6            1.4           0.2   setosa"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = extract_input_output(df, ' species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "num_attribs = list(x)\n",
    "\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "#     ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    #('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "  ])\n",
    "\n",
    "# cat_pipeline = Pipeline([\n",
    "#     ('selector', DataFrameSelector(cat_attribs)),\n",
    "#     ('label_binarizer', MyLabelBinarizer()),\n",
    "#   ])\n",
    "\n",
    "# preprocessor = FeatureUnion(transformer_list=[\n",
    "#     (\"num_pipeline\", num_pipeline),\n",
    "#     (\"cat_pipeline\", cat_pipeline),\n",
    "#   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clf.mlp import MyMlp\n",
    "from clf.utils import read_csv, scale_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "[4, 3]\n"
     ]
    }
   ],
   "source": [
    "input_layer = len(list(x))\n",
    "print(input_layer)\n",
    "output_layer = len(set(y))\n",
    "print(output_layer)\n",
    "hidden_layer = [4, 3]\n",
    "print(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclf = MyMlp(input_layer, hidden_layer, output_layer, epochs=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48439518 0.4137771  0.2409445 ]\n",
      "[0.48439518 0.4137771  0.2409445 ]\n",
      "[0.48439517 0.41377711 0.24094452]\n",
      "[0.11237044 0.27862029 0.68128179]\n",
      "[0.11237044 0.27862029 0.68128179]\n",
      "[0.11237044 0.27862029 0.68128179]\n",
      "[0.73579005 0.25780242 0.05802729]\n",
      "[0.73606992 0.25792291 0.05792918]\n",
      "[0.70552954 0.24660897 0.06955473]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('processor', preprocessor), #Step1 - preprocess data\n",
    "    ('clf', LogisticRegression()) #step2 - classifier (default : LogisticRegression )\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "clfs = []\n",
    "clfs.append(myclf)\n",
    "# clfs.append(SVC())\n",
    "# clfs.append(KNeighborsClassifier(n_neighbors=3))\n",
    "# clfs.append(DecisionTreeClassifier())\n",
    "# clfs.append(RandomForestClassifier())\n",
    "# clfs.append(GradientBoostingClassifier())\n",
    "\n",
    "for classifier in clfs:\n",
    "    pipeline.set_params(clf = classifier)\n",
    "    scores = cross_validate(pipeline, x.values, y.values, cv=5)\n",
    "    print('---------------------------------')\n",
    "    print(str(classifier))\n",
    "    print('-----------------------------------')\n",
    "    for key, values in scores.items():\n",
    "            print(key,' mean ', values.mean())\n",
    "            print(key,' std ', values.std())\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
